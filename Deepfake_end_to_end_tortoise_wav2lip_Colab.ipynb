{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reqK2fYU8RMa"
      },
      "source": [
        "Automatic DeepFake Creation (Tortoise voice cloning + wav2lip)\n",
        "\n",
        "Note: A video is required. If an audio is also provided, the voice will be cloned from the audio.\n",
        "\n",
        "# **The video should have a face looking at all times to the camera.**\n",
        "\n",
        "## **Video (and audio) file should be in Google drive in a folder named 'deepfake'. No other files should exist there**\n",
        "\n",
        "wav2lip code taken from https://github.com/snehitvaddi/Deepfake-using-Wave2Lip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jsyyKrp8osG",
        "outputId": "a354f45b-180c-464c-ed55-ce5d27a979dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#@title Upload video.mp4 (video to overlay voice) & voice.mp3 (voice to clone) files - Should be mp3 and mp4, having any name\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCKcGNEhlP8N",
        "outputId": "80ae5b93-9b70-4953-a4b0-6331feac5dc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/deepfake\n"
          ]
        }
      ],
      "source": [
        "cd gdrive/MyDrive/deepfake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YD5EdXykqXXo"
      },
      "outputs": [],
      "source": [
        "base_path='/content/gdrive/MyDrive/deepfake' #Specify path of video/audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODXQ2Hx3RLWv",
        "outputId": "1d36eefe-86a0-4d4a-ee7b-4c517f6fc1cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m195.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m938.0/938.0 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m113.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n",
            "arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "astropy 6.1.5 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "bigframes 1.25.0 requires numpy>=1.24.0, but you have numpy 1.22.0 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.22.0 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.22.0 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.22.0 which is incompatible.\n",
            "mizani 0.13.0 requires numpy>=1.23.5, but you have numpy 1.22.0 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "numexpr 2.10.1 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.14.1 requires numpy>=1.23.5, but you have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.14.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "pylibraft-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "rmm-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "scikit-image 0.24.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "statsmodels 0.14.4 requires numpy<3,>=1.22.3, but you have numpy 1.22.0 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title Install TTS, pydub to create folders with audio chunks, and moviepy to modify duration of audio/video\n",
        "!pip install -q pydub==0.25.1 TTS==0.22.0 moviepy==1.0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9NAT2EgsCx_o"
      },
      "outputs": [],
      "source": [
        "#@title English text that we want to read with the cloned voice - This will be inserted in the video too\n",
        "#Text prompt should be separated with '|' every one to two sentences (every ~20secs it takes to read it).\n",
        "text_to_read=\"\"\"Joining two modalities results in a surprising increase in generalization! |\n",
        "                What would happen if we combined them all? \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wntESyuu_jcm",
        "outputId": "34b6af8c-43bb-47e5-933d-ed892f665fa3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Voice will be cloned from video\n",
            "MoviePy - Writing audio in input_voice.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                      "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "#@title Rename audio and video files to be used below\n",
        "#Prompt: the user selects and uploads to google colab one audio and one video file. Rename the audio file to 'input_voice.mp3' and the video to 'input_video.mp4'\n",
        "import os\n",
        "\n",
        "# Loop over files in the directory\n",
        "for file in os.listdir(os.getcwd()):\n",
        "\n",
        "      filename = os.path.join(base_path, file)\n",
        "\n",
        "      if filename.endswith('.mp3'):\n",
        "          new_filename = 'input_voice.mp3'\n",
        "          os.rename(filename, new_filename)\n",
        "      if filename.endswith('.mp4'):\n",
        "          new_filename = 'video_full.mp4'\n",
        "          os.rename(filename, new_filename)\n",
        "\n",
        "#If only video is provided:\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def extract_audio(input_video, output_audio):\n",
        "    video = VideoFileClip(input_video)\n",
        "    audio = video.audio\n",
        "    audio.write_audiofile(output_audio)\n",
        "\n",
        "# Provide the input video file path and desired output audio file path\n",
        "input_video = 'video_full.mp4'\n",
        "output_audio = 'input_voice.mp3'\n",
        "\n",
        "#Decide if voice will be cloned from video or audio\n",
        "mp3_check=0\n",
        "for file in os.listdir(os.getcwd()):\n",
        "      file_path =  os.path.join(base_path, file)\n",
        "      if '.mp3' in file_path:\n",
        "        mp3_check=1\n",
        "\n",
        "if mp3_check==0:\n",
        "  print(\"Voice will be cloned from video\")\n",
        "  extract_audio(input_video, output_audio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OekWB8DRAUsh",
        "outputId": "57b0138c-cad5-4d1b-d92d-b4c952516076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15 clips saved in '/content/gdrive/MyDrive/deepfake/voice'.\n"
          ]
        }
      ],
      "source": [
        "#@title Create folder with 10 secs chunks of audio to be used as input in Tortoise\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def split_audio_to_clips(audio_file, output_dir, clip_length=10000, sample_rate=22050):\n",
        "    # Load the audio file\n",
        "    audio = AudioSegment.from_mp3(audio_file)\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Calculate the total number of clips\n",
        "    num_clips = len(audio) // clip_length\n",
        "\n",
        "    # Split the audio into clips and save them as WAV files\n",
        "    for i in range(num_clips):\n",
        "        start_time = i * clip_length\n",
        "        end_time = start_time + clip_length\n",
        "        clip = audio[start_time:end_time]\n",
        "\n",
        "        # Set the sample width to 2 bytes for floating-point format\n",
        "        clip = clip.set_sample_width(2)\n",
        "\n",
        "        # Set the sample rate to 22050 Hz\n",
        "        clip = clip.set_frame_rate(sample_rate)\n",
        "\n",
        "        # Save the clip as a WAV file\n",
        "        clip.export(os.path.join(output_dir, f\"{i+1}.wav\"), format=\"wav\")\n",
        "\n",
        "    print(f\"{num_clips} clips saved in '{output_dir}'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Replace 'input_audio.mp3' with the name of your MP3 file\n",
        "    input_audio_file = base_path+'/input_voice.mp3'\n",
        "\n",
        "    # Replace 'voices' with the desired subdirectory name\n",
        "    subdirectory_name = base_path+'/voice'\n",
        "\n",
        "    split_audio_to_clips(input_audio_file, subdirectory_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYRGVrEe75f9",
        "outputId": "3e7f4cc1-7c9c-482b-9e4d-72275683d3cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Downloading model to /root/.local/share/tts/tts_models--en--multi-dataset--tortoise-v2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1.71G/1.72G [00:21<00:00, 88.0MiB/s]\n",
            "100%|██████████| 1.72G/1.72G [00:22<00:00, 76.1MiB/s]\n",
            "\n",
            "  1%|          | 8.60M/976M [00:00<00:11, 86.0MiB/s]\u001b[A\n",
            "  2%|▏         | 17.2M/976M [00:00<00:12, 76.7MiB/s]\u001b[A\n",
            "  3%|▎         | 24.9M/976M [00:00<00:13, 72.1MiB/s]\u001b[A\n",
            "  3%|▎         | 32.2M/976M [00:00<00:13, 71.1MiB/s]\u001b[A\n",
            "  4%|▍         | 40.5M/976M [00:00<00:12, 75.0MiB/s]\u001b[A\n",
            "  5%|▍         | 48.0M/976M [00:00<00:14, 64.0MiB/s]\u001b[A\n",
            "  6%|▌         | 54.8M/976M [00:00<00:14, 65.2MiB/s]\u001b[A\n",
            "  6%|▋         | 62.9M/976M [00:01<00:18, 48.5MiB/s]\u001b[A\n",
            "  7%|▋         | 71.5M/976M [00:01<00:15, 56.8MiB/s]\u001b[A\n",
            "  8%|▊         | 78.0M/976M [00:01<00:21, 42.0MiB/s]\u001b[A\n",
            "  9%|▊         | 84.5M/976M [00:01<00:19, 46.5MiB/s]\u001b[A\n",
            " 10%|▉         | 94.4M/976M [00:01<00:16, 53.6MiB/s]\u001b[A\n",
            " 11%|█         | 104M/976M [00:01<00:13, 63.1MiB/s] \u001b[A\n",
            " 11%|█▏        | 111M/976M [00:01<00:13, 65.6MiB/s]\u001b[A\n",
            " 12%|█▏        | 118M/976M [00:01<00:12, 66.9MiB/s]\u001b[A\n",
            " 13%|█▎        | 126M/976M [00:02<00:12, 68.5MiB/s]\u001b[A\n",
            " 14%|█▍        | 136M/976M [00:02<00:10, 76.4MiB/s]\u001b[A\n",
            " 15%|█▍        | 143M/976M [00:02<00:11, 69.8MiB/s]\u001b[A\n",
            " 15%|█▌        | 151M/976M [00:02<00:11, 69.8MiB/s]\u001b[A\n",
            " 16%|█▌        | 158M/976M [00:02<00:11, 68.9MiB/s]\u001b[A\n",
            " 17%|█▋        | 168M/976M [00:02<00:10, 76.6MiB/s]\u001b[A\n",
            " 18%|█▊        | 175M/976M [00:02<00:10, 74.3MiB/s]\u001b[A\n",
            " 19%|█▉        | 183M/976M [00:02<00:10, 73.4MiB/s]\u001b[A\n",
            " 20%|█▉        | 190M/976M [00:02<00:10, 73.6MiB/s]\u001b[A\n",
            " 20%|██        | 199M/976M [00:03<00:10, 73.8MiB/s]\u001b[A\n",
            " 21%|██▏       | 208M/976M [00:03<00:09, 78.9MiB/s]\u001b[A\n",
            " 22%|██▏       | 217M/976M [00:03<00:09, 80.4MiB/s]\u001b[A\n",
            " 23%|██▎       | 225M/976M [00:03<00:09, 76.7MiB/s]\u001b[A\n",
            " 24%|██▍       | 233M/976M [00:03<00:09, 76.8MiB/s]\u001b[A\n",
            " 25%|██▍       | 241M/976M [00:03<00:09, 76.5MiB/s]\u001b[A\n",
            " 26%|██▌       | 251M/976M [00:03<00:08, 82.5MiB/s]\u001b[A\n",
            " 27%|██▋       | 259M/976M [00:03<00:08, 79.6MiB/s]\u001b[A\n",
            " 27%|██▋       | 267M/976M [00:03<00:09, 78.4MiB/s]\u001b[A\n",
            " 28%|██▊       | 275M/976M [00:04<00:10, 67.2MiB/s]\u001b[A\n",
            " 29%|██▉       | 282M/976M [00:04<00:11, 59.0MiB/s]\u001b[A\n",
            " 30%|██▉       | 288M/976M [00:04<00:13, 51.9MiB/s]\u001b[A\n",
            " 30%|███       | 295M/976M [00:04<00:12, 55.3MiB/s]\u001b[A\n",
            " 31%|███       | 304M/976M [00:04<00:11, 59.4MiB/s]\u001b[A\n",
            " 32%|███▏      | 314M/976M [00:04<00:09, 68.4MiB/s]\u001b[A\n",
            " 33%|███▎      | 321M/976M [00:04<00:09, 70.4MiB/s]\u001b[A\n",
            " 34%|███▎      | 329M/976M [00:04<00:09, 70.6MiB/s]\u001b[A\n",
            " 34%|███▍      | 336M/976M [00:05<00:08, 71.4MiB/s]\u001b[A\n",
            " 35%|███▌      | 345M/976M [00:05<00:08, 76.8MiB/s]\u001b[A\n",
            " 36%|███▌      | 353M/976M [00:05<00:08, 75.4MiB/s]\u001b[A\n",
            " 37%|███▋      | 360M/976M [00:05<00:12, 47.9MiB/s]\u001b[A\n",
            " 38%|███▊      | 367M/976M [00:05<00:11, 51.8MiB/s]\u001b[A\n",
            " 39%|███▊      | 376M/976M [00:05<00:09, 60.5MiB/s]\u001b[A\n",
            " 39%|███▉      | 384M/976M [00:05<00:09, 64.3MiB/s]\u001b[A\n",
            " 40%|████      | 391M/976M [00:05<00:08, 65.4MiB/s]\u001b[A\n",
            " 41%|████      | 398M/976M [00:06<00:08, 67.8MiB/s]\u001b[A\n",
            " 42%|████▏     | 408M/976M [00:06<00:07, 75.9MiB/s]\u001b[A\n",
            " 43%|████▎     | 416M/976M [00:06<00:07, 74.0MiB/s]\u001b[A\n",
            " 43%|████▎     | 424M/976M [00:06<00:07, 73.4MiB/s]\u001b[A\n",
            " 44%|████▍     | 431M/976M [00:06<00:07, 73.8MiB/s]\u001b[A\n",
            " 45%|████▌     | 440M/976M [00:06<00:07, 73.8MiB/s]\u001b[A\n",
            " 46%|████▌     | 450M/976M [00:06<00:06, 79.8MiB/s]\u001b[A\n",
            " 47%|████▋     | 458M/976M [00:06<00:06, 78.4MiB/s]\u001b[A\n",
            " 48%|████▊     | 466M/976M [00:06<00:07, 67.3MiB/s]\u001b[A\n",
            " 48%|████▊     | 473M/976M [00:07<00:09, 54.5MiB/s]\u001b[A\n",
            " 49%|████▉     | 482M/976M [00:07<00:08, 60.1MiB/s]\u001b[A\n",
            " 50%|█████     | 492M/976M [00:07<00:07, 67.5MiB/s]\u001b[A\n",
            " 51%|█████     | 499M/976M [00:07<00:07, 66.6MiB/s]\u001b[A\n",
            " 52%|█████▏    | 506M/976M [00:07<00:06, 68.6MiB/s]\u001b[A\n",
            " 53%|█████▎    | 514M/976M [00:07<00:06, 68.8MiB/s]\u001b[A\n",
            " 54%|█████▎    | 524M/976M [00:07<00:05, 76.9MiB/s]\u001b[A\n",
            " 54%|█████▍    | 532M/976M [00:07<00:05, 75.8MiB/s]\u001b[A\n",
            " 55%|█████▌    | 539M/976M [00:08<00:06, 69.1MiB/s]\u001b[A\n",
            " 56%|█████▌    | 546M/976M [00:08<00:06, 69.0MiB/s]\u001b[A\n",
            " 57%|█████▋    | 556M/976M [00:08<00:05, 75.6MiB/s]\u001b[A\n",
            " 58%|█████▊    | 563M/976M [00:08<00:05, 74.9MiB/s]\u001b[A\n",
            " 59%|█████▊    | 571M/976M [00:08<00:05, 74.7MiB/s]\u001b[A\n",
            " 59%|█████▉    | 579M/976M [00:08<00:05, 76.0MiB/s]\u001b[A\n",
            " 60%|██████    | 587M/976M [00:08<00:05, 74.8MiB/s]\u001b[A\n",
            " 61%|██████    | 597M/976M [00:08<00:04, 82.2MiB/s]\u001b[A\n",
            " 62%|██████▏   | 606M/976M [00:08<00:04, 79.6MiB/s]\u001b[A\n",
            " 63%|██████▎   | 614M/976M [00:08<00:04, 74.6MiB/s]\u001b[A\n",
            " 64%|██████▎   | 621M/976M [00:09<00:04, 75.6MiB/s]\u001b[A\n",
            " 64%|██████▍   | 629M/976M [00:09<00:04, 72.7MiB/s]\u001b[A\n",
            " 65%|██████▌   | 639M/976M [00:09<00:04, 78.6MiB/s]\u001b[A\n",
            " 66%|██████▋   | 647M/976M [00:09<00:04, 75.0MiB/s]\u001b[A\n",
            " 67%|██████▋   | 654M/976M [00:09<00:04, 71.9MiB/s]\u001b[A\n",
            " 68%|██████▊   | 661M/976M [00:09<00:04, 67.9MiB/s]\u001b[A\n",
            " 69%|██████▉   | 671M/976M [00:09<00:04, 69.5MiB/s]\u001b[A\n",
            " 70%|██████▉   | 679M/976M [00:09<00:04, 72.0MiB/s]\u001b[A\n",
            " 70%|███████   | 687M/976M [00:10<00:04, 68.8MiB/s]\u001b[A\n",
            " 71%|███████   | 694M/976M [00:10<00:04, 68.3MiB/s]\u001b[A\n",
            " 72%|███████▏  | 703M/976M [00:10<00:03, 70.0MiB/s]\u001b[A\n",
            " 73%|███████▎  | 712M/976M [00:10<00:03, 77.1MiB/s]\u001b[A\n",
            " 74%|███████▍  | 720M/976M [00:10<00:03, 76.5MiB/s]\u001b[A\n",
            " 75%|███████▍  | 728M/976M [00:10<00:03, 75.5MiB/s]\u001b[A\n",
            " 75%|███████▌  | 735M/976M [00:10<00:03, 65.1MiB/s]\u001b[A\n",
            " 76%|███████▋  | 744M/976M [00:10<00:03, 68.7MiB/s]\u001b[A\n",
            " 77%|███████▋  | 754M/976M [00:10<00:02, 76.4MiB/s]\u001b[A\n",
            " 78%|███████▊  | 762M/976M [00:11<00:02, 76.3MiB/s]\u001b[A\n",
            " 79%|███████▉  | 770M/976M [00:11<00:02, 76.0MiB/s]\u001b[A\n",
            " 80%|███████▉  | 778M/976M [00:11<00:02, 75.3MiB/s]\u001b[A\n",
            " 81%|████████  | 786M/976M [00:11<00:02, 75.2MiB/s]\u001b[A\n",
            " 82%|████████▏ | 796M/976M [00:11<00:02, 81.9MiB/s]\u001b[A\n",
            " 82%|████████▏ | 805M/976M [00:11<00:02, 78.9MiB/s]\u001b[A\n",
            " 83%|████████▎ | 813M/976M [00:11<00:02, 67.4MiB/s]\u001b[A\n",
            " 84%|████████▍ | 820M/976M [00:11<00:02, 67.5MiB/s]\u001b[A\n",
            " 85%|████████▍ | 828M/976M [00:11<00:02, 69.3MiB/s]\u001b[A\n",
            " 86%|████████▌ | 838M/976M [00:12<00:01, 75.7MiB/s]\u001b[A\n",
            " 87%|████████▋ | 845M/976M [00:12<00:02, 44.8MiB/s]\u001b[A\n",
            " 87%|████████▋ | 852M/976M [00:12<00:02, 48.8MiB/s]\u001b[A\n",
            " 88%|████████▊ | 860M/976M [00:12<00:02, 53.6MiB/s]\u001b[A\n",
            " 89%|████████▉ | 867M/976M [00:12<00:01, 57.8MiB/s]\u001b[A\n",
            " 90%|████████▉ | 874M/976M [00:12<00:02, 43.7MiB/s]\u001b[A\n",
            " 90%|█████████ | 881M/976M [00:13<00:02, 37.5MiB/s]\u001b[A\n",
            " 91%|█████████ | 890M/976M [00:13<00:01, 46.6MiB/s]\u001b[A\n",
            " 92%|█████████▏| 897M/976M [00:13<00:01, 52.8MiB/s]\u001b[A\n",
            " 93%|█████████▎| 904M/976M [00:13<00:01, 56.1MiB/s]\u001b[A\n",
            " 94%|█████████▎| 912M/976M [00:13<00:01, 60.7MiB/s]\u001b[A\n",
            " 94%|█████████▍| 920M/976M [00:13<00:00, 66.1MiB/s]\u001b[A\n",
            " 95%|█████████▌| 928M/976M [00:13<00:00, 68.9MiB/s]\u001b[A\n",
            " 96%|█████████▌| 935M/976M [00:13<00:00, 68.7MiB/s]\u001b[A\n",
            " 97%|█████████▋| 944M/976M [00:14<00:00, 59.3MiB/s]\u001b[A\n",
            " 98%|█████████▊| 953M/976M [00:14<00:00, 67.1MiB/s]\u001b[A\n",
            " 98%|█████████▊| 960M/976M [00:14<00:00, 69.0MiB/s]\u001b[A\n",
            " 99%|█████████▉| 968M/976M [00:14<00:00, 70.8MiB/s]\u001b[A\n",
            "100%|██████████| 976M/976M [00:15<00:00, 63.9MiB/s]\n",
            " 99%|█████████▉| 150M/151M [00:03<00:00, 24.5MiB/s]\n",
            "100%|██████████| 151M/151M [00:04<00:00, 35.6MiB/s]\n",
            "\n",
            "  1%|          | 8.35M/1.17G [00:00<00:13, 83.5MiB/s]\u001b[A\n",
            "  2%|▏         | 17.8M/1.17G [00:00<00:12, 90.0MiB/s]\u001b[A\n",
            "  2%|▏         | 26.8M/1.17G [00:00<00:12, 89.9MiB/s]\u001b[A\n",
            "  3%|▎         | 35.8M/1.17G [00:00<00:12, 90.1MiB/s]\u001b[A\n",
            "  4%|▍         | 45.1M/1.17G [00:00<00:12, 91.0MiB/s]\u001b[A\n",
            "  5%|▍         | 55.0M/1.17G [00:00<00:11, 93.7MiB/s]\u001b[A\n",
            "  6%|▌         | 65.0M/1.17G [00:00<00:11, 95.6MiB/s]\u001b[A\n",
            "  6%|▋         | 74.7M/1.17G [00:00<00:11, 96.2MiB/s]\u001b[A\n",
            "  7%|▋         | 84.3M/1.17G [00:00<00:11, 95.3MiB/s]\u001b[A\n",
            "  8%|▊         | 94.3M/1.17G [00:01<00:11, 96.4MiB/s]\u001b[A\n",
            "  9%|▉         | 104M/1.17G [00:01<00:11, 95.0MiB/s] \u001b[A\n",
            " 10%|▉         | 113M/1.17G [00:01<00:11, 94.3MiB/s]\u001b[A\n",
            " 11%|█         | 123M/1.17G [00:01<00:11, 91.2MiB/s]\u001b[A\n",
            " 11%|█▏        | 132M/1.17G [00:01<00:12, 85.2MiB/s]\u001b[A\n",
            " 12%|█▏        | 141M/1.17G [00:01<00:11, 86.2MiB/s]\u001b[A\n",
            " 13%|█▎        | 150M/1.17G [00:01<00:11, 88.3MiB/s]\u001b[A\n",
            " 14%|█▎        | 159M/1.17G [00:01<00:11, 89.4MiB/s]\u001b[A\n",
            " 14%|█▍        | 168M/1.17G [00:01<00:11, 89.4MiB/s]\u001b[A\n",
            " 15%|█▌        | 178M/1.17G [00:01<00:11, 89.7MiB/s]\u001b[A\n",
            " 16%|█▌        | 188M/1.17G [00:02<00:10, 91.8MiB/s]\u001b[A\n",
            " 17%|█▋        | 198M/1.17G [00:02<00:10, 93.4MiB/s]\u001b[A\n",
            " 18%|█▊        | 207M/1.17G [00:02<00:14, 68.6MiB/s]\u001b[A\n",
            " 18%|█▊        | 215M/1.17G [00:02<00:16, 58.4MiB/s]\u001b[A\n",
            " 19%|█▉        | 224M/1.17G [00:02<00:14, 65.2MiB/s]\u001b[A\n",
            " 20%|█▉        | 233M/1.17G [00:02<00:13, 70.8MiB/s]\u001b[A\n",
            " 21%|██        | 242M/1.17G [00:02<00:11, 77.7MiB/s]\u001b[A\n",
            " 22%|██▏       | 252M/1.17G [00:02<00:11, 80.4MiB/s]\u001b[A\n",
            " 22%|██▏       | 261M/1.17G [00:03<00:10, 85.2MiB/s]\u001b[A\n",
            " 23%|██▎       | 271M/1.17G [00:03<00:10, 87.3MiB/s]\u001b[A\n",
            " 24%|██▍       | 281M/1.17G [00:03<00:09, 90.5MiB/s]\u001b[A\n",
            " 25%|██▍       | 290M/1.17G [00:03<00:10, 83.9MiB/s]\u001b[A\n",
            " 26%|██▌       | 298M/1.17G [00:03<00:10, 80.2MiB/s]\u001b[A\n",
            " 26%|██▋       | 307M/1.17G [00:03<00:10, 82.6MiB/s]\u001b[A\n",
            " 27%|██▋       | 316M/1.17G [00:03<00:10, 83.6MiB/s]\u001b[A\n",
            " 28%|██▊       | 325M/1.17G [00:03<00:09, 85.5MiB/s]\u001b[A\n",
            " 29%|██▊       | 334M/1.17G [00:03<00:10, 81.9MiB/s]\u001b[A\n",
            " 29%|██▉       | 343M/1.17G [00:04<00:09, 84.4MiB/s]\u001b[A\n",
            " 30%|███       | 351M/1.17G [00:04<00:10, 77.6MiB/s]\u001b[A\n",
            " 31%|███       | 361M/1.17G [00:04<00:09, 83.2MiB/s]\u001b[A\n",
            " 32%|███▏      | 371M/1.17G [00:04<00:09, 86.8MiB/s]\u001b[A\n",
            " 32%|███▏      | 379M/1.17G [00:04<00:17, 45.1MiB/s]\u001b[A\n",
            " 33%|███▎      | 388M/1.17G [00:05<00:17, 44.1MiB/s]\u001b[A\n",
            " 34%|███▍      | 397M/1.17G [00:05<00:14, 52.2MiB/s]\u001b[A\n",
            " 35%|███▍      | 404M/1.17G [00:05<00:14, 51.1MiB/s]\u001b[A\n",
            " 35%|███▌      | 412M/1.17G [00:05<00:13, 56.8MiB/s]\u001b[A\n",
            " 36%|███▌      | 421M/1.17G [00:05<00:11, 63.9MiB/s]\u001b[A\n",
            " 37%|███▋      | 428M/1.17G [00:05<00:11, 64.0MiB/s]\u001b[A\n",
            " 37%|███▋      | 435M/1.17G [00:05<00:15, 47.9MiB/s]\u001b[A\n",
            " 38%|███▊      | 443M/1.17G [00:05<00:13, 55.2MiB/s]\u001b[A\n",
            " 39%|███▊      | 453M/1.17G [00:06<00:11, 63.6MiB/s]\u001b[A\n",
            " 39%|███▉      | 462M/1.17G [00:06<00:10, 70.5MiB/s]\u001b[A\n",
            " 40%|████      | 471M/1.17G [00:06<00:09, 76.5MiB/s]\u001b[A\n",
            " 41%|████      | 480M/1.17G [00:06<00:08, 79.0MiB/s]\u001b[A\n",
            " 42%|████▏     | 489M/1.17G [00:06<00:08, 83.7MiB/s]\u001b[A\n",
            " 43%|████▎     | 498M/1.17G [00:06<00:08, 83.9MiB/s]\u001b[A\n",
            " 43%|████▎     | 507M/1.17G [00:06<00:07, 84.9MiB/s]\u001b[A\n",
            " 44%|████▍     | 515M/1.17G [00:06<00:07, 84.7MiB/s]\u001b[A\n",
            " 45%|████▍     | 525M/1.17G [00:06<00:07, 87.5MiB/s]\u001b[A\n",
            " 46%|████▌     | 534M/1.17G [00:06<00:07, 89.6MiB/s]\u001b[A\n",
            " 47%|████▋     | 544M/1.17G [00:07<00:06, 91.9MiB/s]\u001b[A\n",
            " 47%|████▋     | 553M/1.17G [00:07<00:07, 86.4MiB/s]\u001b[A\n",
            " 48%|████▊     | 562M/1.17G [00:07<00:07, 86.2MiB/s]\u001b[A\n",
            " 49%|████▉     | 571M/1.17G [00:07<00:06, 88.1MiB/s]\u001b[A\n",
            " 50%|████▉     | 580M/1.17G [00:07<00:06, 85.8MiB/s]\u001b[A\n",
            " 50%|█████     | 590M/1.17G [00:07<00:06, 88.9MiB/s]\u001b[A\n",
            " 51%|█████     | 599M/1.17G [00:07<00:06, 87.8MiB/s]\u001b[A\n",
            " 52%|█████▏    | 608M/1.17G [00:07<00:06, 89.2MiB/s]\u001b[A\n",
            " 53%|█████▎    | 617M/1.17G [00:07<00:06, 88.7MiB/s]\u001b[A\n",
            " 54%|█████▎    | 626M/1.17G [00:07<00:06, 85.9MiB/s]\u001b[A\n",
            " 54%|█████▍    | 635M/1.17G [00:08<00:06, 86.5MiB/s]\u001b[A\n",
            " 55%|█████▌    | 644M/1.17G [00:08<00:05, 88.7MiB/s]\u001b[A\n",
            " 56%|█████▌    | 654M/1.17G [00:08<00:05, 91.3MiB/s]\u001b[A\n",
            " 57%|█████▋    | 663M/1.17G [00:08<00:05, 91.0MiB/s]\u001b[A\n",
            " 57%|█████▋    | 672M/1.17G [00:08<00:05, 90.2MiB/s]\u001b[A\n",
            " 58%|█████▊    | 682M/1.17G [00:08<00:05, 92.6MiB/s]\u001b[A\n",
            " 59%|█████▉    | 692M/1.17G [00:08<00:05, 94.0MiB/s]\u001b[A\n",
            " 60%|█████▉    | 701M/1.17G [00:08<00:04, 95.3MiB/s]\u001b[A\n",
            " 61%|██████    | 711M/1.17G [00:08<00:04, 96.3MiB/s]\u001b[A\n",
            " 62%|██████▏   | 721M/1.17G [00:08<00:04, 95.8MiB/s]\u001b[A\n",
            " 62%|██████▏   | 731M/1.17G [00:09<00:04, 93.0MiB/s]\u001b[A\n",
            " 63%|██████▎   | 740M/1.17G [00:09<00:04, 91.3MiB/s]\u001b[A\n",
            " 64%|██████▍   | 749M/1.17G [00:09<00:04, 88.6MiB/s]\u001b[A\n",
            " 65%|██████▍   | 759M/1.17G [00:09<00:04, 90.6MiB/s]\u001b[A\n",
            " 66%|██████▌   | 768M/1.17G [00:09<00:04, 89.0MiB/s]\u001b[A\n",
            " 66%|██████▋   | 777M/1.17G [00:09<00:04, 90.0MiB/s]\u001b[A\n",
            " 67%|██████▋   | 786M/1.17G [00:09<00:05, 74.2MiB/s]\u001b[A\n",
            " 68%|██████▊   | 794M/1.17G [00:09<00:05, 65.4MiB/s]\u001b[A\n",
            " 69%|██████▊   | 802M/1.17G [00:10<00:05, 70.3MiB/s]\u001b[A\n",
            " 69%|██████▉   | 812M/1.17G [00:10<00:04, 75.8MiB/s]\u001b[A\n",
            " 70%|███████   | 821M/1.17G [00:10<00:04, 81.2MiB/s]\u001b[A\n",
            " 71%|███████   | 830M/1.17G [00:10<00:05, 57.9MiB/s]\u001b[A\n",
            " 72%|███████▏  | 839M/1.17G [00:10<00:05, 63.7MiB/s]\u001b[A\n",
            " 73%|███████▎  | 849M/1.17G [00:10<00:04, 71.6MiB/s]\u001b[A\n",
            " 73%|███████▎  | 857M/1.17G [00:10<00:04, 72.8MiB/s]\u001b[A\n",
            " 74%|███████▍  | 865M/1.17G [00:10<00:04, 71.7MiB/s]\u001b[A\n",
            " 75%|███████▍  | 872M/1.17G [00:11<00:05, 57.3MiB/s]\u001b[A\n",
            " 75%|███████▌  | 881M/1.17G [00:11<00:04, 65.1MiB/s]\u001b[A\n",
            " 76%|███████▌  | 891M/1.17G [00:11<00:03, 73.0MiB/s]\u001b[A\n",
            " 77%|███████▋  | 901M/1.17G [00:11<00:03, 80.1MiB/s]\u001b[A\n",
            " 78%|███████▊  | 911M/1.17G [00:11<00:03, 85.3MiB/s]\u001b[A\n",
            " 79%|███████▊  | 920M/1.17G [00:11<00:02, 86.6MiB/s]\u001b[A\n",
            " 79%|███████▉  | 929M/1.17G [00:11<00:02, 88.0MiB/s]\u001b[A\n",
            " 80%|████████  | 938M/1.17G [00:11<00:03, 76.4MiB/s]\u001b[A\n",
            " 81%|████████  | 946M/1.17G [00:12<00:03, 60.3MiB/s]\u001b[A\n",
            " 82%|████████▏ | 956M/1.17G [00:12<00:03, 67.5MiB/s]\u001b[A\n",
            " 82%|████████▏ | 965M/1.17G [00:12<00:02, 68.3MiB/s]\u001b[A\n",
            " 83%|████████▎ | 972M/1.17G [00:12<00:02, 68.6MiB/s]\u001b[A\n",
            " 84%|████████▍ | 981M/1.17G [00:12<00:02, 72.9MiB/s]\u001b[A\n",
            " 85%|████████▍ | 991M/1.17G [00:12<00:02, 80.0MiB/s]\u001b[A\n",
            " 85%|████████▌ | 999M/1.17G [00:12<00:02, 76.7MiB/s]\u001b[A\n",
            " 86%|████████▌ | 1.01G/1.17G [00:12<00:02, 80.1MiB/s]\u001b[A\n",
            " 87%|████████▋ | 1.02G/1.17G [00:12<00:01, 85.8MiB/s]\u001b[A\n",
            " 88%|████████▊ | 1.03G/1.17G [00:13<00:01, 86.4MiB/s]\u001b[A\n",
            " 89%|████████▊ | 1.04G/1.17G [00:13<00:01, 87.2MiB/s]\u001b[A\n",
            " 89%|████████▉ | 1.05G/1.17G [00:13<00:01, 86.0MiB/s]\u001b[A\n",
            " 90%|█████████ | 1.05G/1.17G [00:13<00:01, 87.5MiB/s]\u001b[A\n",
            " 91%|█████████ | 1.06G/1.17G [00:13<00:01, 90.9MiB/s]\u001b[A\n",
            " 92%|█████████▏| 1.07G/1.17G [00:13<00:01, 90.9MiB/s]\u001b[A\n",
            " 93%|█████████▎| 1.08G/1.17G [00:13<00:01, 84.8MiB/s]\u001b[A\n",
            " 93%|█████████▎| 1.09G/1.17G [00:13<00:00, 83.4MiB/s]\u001b[A\n",
            " 94%|█████████▍| 1.10G/1.17G [00:13<00:00, 87.4MiB/s]\u001b[A\n",
            " 95%|█████████▍| 1.11G/1.17G [00:14<00:00, 68.6MiB/s]\u001b[A\n",
            " 96%|█████████▌| 1.12G/1.17G [00:14<00:00, 70.0MiB/s]\u001b[A\n",
            " 96%|█████████▌| 1.12G/1.17G [00:14<00:00, 69.2MiB/s]\u001b[A\n",
            " 97%|█████████▋| 1.13G/1.17G [00:14<00:00, 75.3MiB/s]\u001b[A\n",
            " 98%|█████████▊| 1.14G/1.17G [00:14<00:00, 77.8MiB/s]\u001b[A\n",
            " 99%|█████████▊| 1.15G/1.17G [00:14<00:00, 83.3MiB/s]\u001b[A\n",
            "100%|██████████| 1.17G/1.17G [00:15<00:00, 75.2MiB/s]\n",
            " 94%|█████████▍| 23.7M/25.2M [00:00<00:00, 75.1MiB/s]\n",
            "100%|██████████| 25.2M/25.2M [00:01<00:00, 24.8MiB/s]\n",
            "\n",
            "  8%|▊         | 8.34M/101M [00:00<00:01, 83.4MiB/s]\u001b[A\n",
            " 17%|█▋        | 16.7M/101M [00:00<00:01, 71.7MiB/s]\u001b[A\n",
            " 25%|██▍       | 25.0M/101M [00:00<00:00, 76.5MiB/s]\u001b[A\n",
            " 33%|███▎      | 32.8M/101M [00:00<00:00, 76.8MiB/s]\u001b[A\n",
            " 41%|████      | 41.2M/101M [00:00<00:00, 79.6MiB/s]\u001b[A\n",
            " 49%|████▉     | 49.3M/101M [00:00<00:00, 80.1MiB/s]\u001b[A\n",
            " 57%|█████▋    | 57.7M/101M [00:00<00:00, 81.1MiB/s]\u001b[A\n",
            " 66%|██████▌   | 66.2M/101M [00:00<00:00, 82.3MiB/s]\u001b[A\n",
            " 74%|███████▍  | 74.4M/101M [00:00<00:00, 81.8MiB/s]\u001b[A\n",
            " 83%|████████▎ | 83.6M/101M [00:01<00:00, 84.9MiB/s]\u001b[A\n",
            " 91%|█████████▏| 92.1M/101M [00:01<00:00, 83.8MiB/s]\u001b[A\n",
            "100%|██████████| 101M/101M [00:01<00:00, 51.9MiB/s]\n",
            " 98%|█████████▊| 384M/391M [00:04<00:00, 82.7MiB/s]\n",
            "100%|██████████| 391M/391M [00:05<00:00, 71.2MiB/s]\n",
            "100%|██████████| 1.07k/1.07k [00:00<00:00, 1.58kiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Model's license - apache 2.0\n",
            " > Check https://choosealicense.com/licenses/apache-2.0/ for more info.\n",
            " > Using model: tortoise\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/TTS/tts/models/tortoise.py:881: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(ar_path, map_location=torch.device(\"cpu\"))\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/TTS/tts/models/tortoise.py:888: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.diffusion.load_state_dict(torch.load(diff_path), strict=strict)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/TTS/tts/models/tortoise.py:891: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.clvp.load_state_dict(torch.load(clvp_path), strict=strict)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/TTS/tts/models/tortoise.py:896: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  torch.load(\n",
            "\n",
            "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
          ]
        }
      ],
      "source": [
        "#@title Download and run TTS tortoise model\n",
        "from TTS.api import TTS\n",
        "tts = TTS(\"tts_models/en/multi-dataset/tortoise-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IPxbWjtILaPR",
        "outputId": "c2a3ff24-c296-45da-c58c-2fcc5834566e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Collecting scipy\n",
            "  Using cached scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting numpy<2.3,>=1.23.5 (from scipy)\n",
            "  Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.0\n",
            "    Uninstalling numpy-1.22.0:\n",
            "      Successfully uninstalled numpy-1.22.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tts 0.22.0 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 2.1.3 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.1.3 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.3 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\n",
            "gruut 2.2.3 requires numpy<2.0.0,>=1.19.0, but you have numpy 2.1.3 which is incompatible.\n",
            "langchain 0.3.7 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.1.3 which is incompatible.\n",
            "matplotlib 3.8.0 requires numpy<2,>=1.21, but you have numpy 2.1.3 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "plotnine 0.14.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "pytensor 2.25.5 requires numpy<2,>=1.17.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.3 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.3 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.1.3 scipy-1.14.1\n",
            "Cloning into 'tortoise-tts'...\n",
            "remote: Enumerating objects: 1481, done.\u001b[K\n",
            "remote: Total 1481 (delta 0), reused 0 (delta 0), pack-reused 1481 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1481/1481), 53.56 MiB | 24.11 MiB/s, done.\n",
            "Resolving deltas: 100% (604/604), done.\n",
            "Updating files: 100% (558/558), done.\n",
            "/content/gdrive/MyDrive/deepfake/tortoise-tts\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.66.6)\n",
            "Collecting rotary_embedding_torch (from -r requirements.txt (line 2))\n",
            "  Downloading rotary_embedding_torch-0.8.5-py3-none-any.whl.metadata (678 bytes)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.46.2)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.20.3)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (7.4.0)\n",
            "Collecting progressbar (from -r requirements.txt (line 6))\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.8.0)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.3.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.14.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.10.0)\n",
            "Collecting numba==0.48.0 (from -r requirements.txt (line 11))\n",
            "  Downloading numba-0.48.0.tar.gz (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ffmpeg (from -r requirements.txt (line 12))\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting llvmlite<0.32.0,>=0.31.0dev0 (from numba==0.48.0->-r requirements.txt (line 11))\n",
            "  Downloading llvmlite-0.31.0.tar.gz (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from numba==0.48.0->-r requirements.txt (line 11)) (2.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba==0.48.0->-r requirements.txt (line 11)) (75.1.0)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from rotary_embedding_torch->-r requirements.txt (line 2)) (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (0.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (0.4.5)\n",
            "Requirement already satisfied: more-itertools>=8.5.0 in /usr/local/lib/python3.10/dist-packages (from inflect->-r requirements.txt (line 5)) (10.5.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from inflect->-r requirements.txt (line 5)) (4.4.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (4.4.2)\n",
            "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting librosa (from -r requirements.txt (line 10))\n",
            "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Using cached librosa-0.10.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Using cached librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Using cached librosa-0.10.0.post2-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Using cached librosa-0.10.0.post1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting resampy>=0.2.2 (from librosa->-r requirements.txt (line 10))\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (1.8.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers->-r requirements.txt (line 3)) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers->-r requirements.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->-r requirements.txt (line 10)) (4.3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2024.8.30)\n",
            "INFO: pip is looking at multiple versions of resampy to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading resampy-0.4.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading resampy-0.4.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading resampy-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->-r requirements.txt (line 10)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa->-r requirements.txt (line 10)) (1.17.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary_embedding_torch->-r requirements.txt (line 2)) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary_embedding_torch->-r requirements.txt (line 2)) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary_embedding_torch->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0->rotary_embedding_torch->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->-r requirements.txt (line 10)) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->rotary_embedding_torch->-r requirements.txt (line 2)) (3.0.2)\n",
            "Downloading rotary_embedding_torch-0.8.5-py3-none-any.whl (5.6 kB)\n",
            "Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: numba, progressbar, ffmpeg, llvmlite\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for numba (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for numba\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for numba\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12066 sha256=3109698279b9a62f4a6a78f3adb7b699a0a15fd9f195a32643887ab5e9c253f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/17/e5/765d1a3112ff3978f70223502f6047e06c43a24d7c5f8ff95b\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=0bec778e044de9c8498d806774dac92491985c0b2b01e8ef6c262e219fc9e810\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for llvmlite (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for llvmlite\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for llvmlite\n",
            "Successfully built progressbar ffmpeg\n",
            "Failed to build numba llvmlite\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (numba, llvmlite)\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting transformers==4.19.0\n",
            "  Downloading transformers-4.19.0-py3-none-any.whl.metadata (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.5.0\n",
            "  Downloading einops-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting rotary_embedding_torch==0.1.5\n",
            "  Downloading rotary_embedding_torch-0.1.5-py3-none-any.whl.metadata (669 bytes)\n",
            "Collecting unidecode==1.3.5\n",
            "  Downloading Unidecode-1.3.5-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (2.1.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.19.0)\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from rotary_embedding_torch==0.1.5) (2.5.0+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->rotary_embedding_torch==0.1.5) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->rotary_embedding_torch==0.1.5) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->rotary_embedding_torch==0.1.5) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6->rotary_embedding_torch==0.1.5) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->rotary_embedding_torch==0.1.5) (3.0.2)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'unidecode' candidate (version 1.3.5 at https://files.pythonhosted.org/packages/7c/bb/a1cea9ce56434cdb59cb4c8b7bf91b190011b7000fb0a12b44fa0a3daa86/Unidecode-1.3.5-py3-none-any.whl (from https://pypi.org/simple/unidecode/) (requires-python:>=3.5))\n",
            "Reason for being yanked: wrong version of the code was released in the .whl package\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading transformers-4.19.0-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.5.0-py3-none-any.whl (36 kB)\n",
            "Downloading rotary_embedding_torch-0.1.5-py3-none-any.whl (4.1 kB)\n",
            "Downloading Unidecode-1.3.5-py3-none-any.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.5/236.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, unidecode, einops, transformers, rotary_embedding_torch\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: unidecode\n",
            "    Found existing installation: Unidecode 1.3.8\n",
            "    Uninstalling Unidecode-1.3.8:\n",
            "      Successfully uninstalled Unidecode-1.3.8\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.0\n",
            "    Uninstalling einops-0.8.0:\n",
            "      Successfully uninstalled einops-0.8.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.2\n",
            "    Uninstalling transformers-4.46.2:\n",
            "      Successfully uninstalled transformers-4.46.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tts 0.22.0 requires einops>=0.6.0, but you have einops 0.5.0 which is incompatible.\n",
            "tts 0.22.0 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 2.1.3 which is incompatible.\n",
            "tts 0.22.0 requires transformers>=4.33.0, but you have transformers 4.19.0 which is incompatible.\n",
            "sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed einops-0.5.0 rotary_embedding_torch-0.1.5 tokenizers-0.12.1 transformers-4.19.0 unidecode-1.3.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "9f755ab76b97486bac963cfa9f166812",
              "pip_warning": {
                "packages": [
                  "tokenizers",
                  "transformers"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating TorToiSe.egg-info\n",
            "writing TorToiSe.egg-info/PKG-INFO\n",
            "writing dependency_links to TorToiSe.egg-info/dependency_links.txt\n",
            "writing requirements to TorToiSe.egg-info/requires.txt\n",
            "writing top-level names to TorToiSe.egg-info/top_level.txt\n",
            "writing manifest file 'TorToiSe.egg-info/SOURCES.txt'\n",
            "reading manifest file 'TorToiSe.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'TorToiSe.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/lib/tortoise\n",
            "copying tortoise/__init__.py -> build/lib/tortoise\n",
            "copying tortoise/api.py -> build/lib/tortoise\n",
            "copying tortoise/do_tts.py -> build/lib/tortoise\n",
            "copying tortoise/eval.py -> build/lib/tortoise\n",
            "copying tortoise/get_conditioning_latents.py -> build/lib/tortoise\n",
            "copying tortoise/is_this_from_tortoise.py -> build/lib/tortoise\n",
            "copying tortoise/read.py -> build/lib/tortoise\n",
            "creating build/lib/tortoise/models\n",
            "copying tortoise/models/__init__.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/arch_util.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/autoregressive.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/classifier.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/clvp.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/cvvp.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/diffusion_decoder.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/random_latent_generator.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/transformer.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/vocoder.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/xtransformers.py -> build/lib/tortoise/models\n",
            "creating build/lib/tortoise/utils\n",
            "copying tortoise/utils/__init__.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/audio.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/diffusion.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/samples_generator.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/stft.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/text.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/tokenizer.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/typical_sampling.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/wav2vec_alignment.py -> build/lib/tortoise/utils\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/tortoise\n",
            "copying build/lib/tortoise/__init__.py -> build/bdist.linux-x86_64/egg/tortoise\n",
            "copying build/lib/tortoise/api.py -> build/bdist.linux-x86_64/egg/tortoise\n",
            "copying build/lib/tortoise/do_tts.py -> build/bdist.linux-x86_64/egg/tortoise\n",
            "copying build/lib/tortoise/eval.py -> build/bdist.linux-x86_64/egg/tortoise\n",
            "copying build/lib/tortoise/get_conditioning_latents.py -> build/bdist.linux-x86_64/egg/tortoise\n",
            "copying build/lib/tortoise/is_this_from_tortoise.py -> build/bdist.linux-x86_64/egg/tortoise\n",
            "copying build/lib/tortoise/read.py -> build/bdist.linux-x86_64/egg/tortoise\n",
            "creating build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/__init__.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/arch_util.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/autoregressive.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/classifier.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/clvp.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/cvvp.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/diffusion_decoder.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/random_latent_generator.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/transformer.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/vocoder.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/xtransformers.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "creating build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/__init__.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/audio.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/diffusion.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/samples_generator.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/stft.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/text.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/tokenizer.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/typical_sampling.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/wav2vec_alignment.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/api.py to api.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/do_tts.py to do_tts.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/eval.py to eval.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/get_conditioning_latents.py to get_conditioning_latents.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/is_this_from_tortoise.py to is_this_from_tortoise.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/read.py to read.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/arch_util.py to arch_util.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/autoregressive.py to autoregressive.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/classifier.py to classifier.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/clvp.py to clvp.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/cvvp.py to cvvp.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/diffusion_decoder.py to diffusion_decoder.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/random_latent_generator.py to random_latent_generator.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/transformer.py to transformer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/vocoder.py to vocoder.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/xtransformers.py to xtransformers.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/audio.py to audio.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/diffusion.py to diffusion.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/samples_generator.py to samples_generator.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/stft.py to stft.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/text.py to text.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/tokenizer.py to tokenizer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/typical_sampling.py to typical_sampling.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/wav2vec_alignment.py to wav2vec_alignment.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TorToiSe.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TorToiSe.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TorToiSe.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TorToiSe.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TorToiSe.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/TorToiSe-2.3.0-py3.10.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing TorToiSe-2.3.0-py3.10.egg\n",
            "Copying TorToiSe-2.3.0-py3.10.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding TorToiSe 2.3.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/TorToiSe-2.3.0-py3.10.egg\n",
            "Processing dependencies for TorToiSe==2.3.0\n",
            "Searching for progressbar\n",
            "Reading https://pypi.org/simple/progressbar/\n",
            "Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz#sha256=5d81cb529da2e223b53962afd6c8ca0f05c6670e40309a7219eacc36af9b6c63\n",
            "Best match: progressbar 2.5\n",
            "Processing progressbar-2.5.tar.gz\n",
            "Writing /tmp/easy_install-1z2jmdn9/progressbar-2.5/setup.cfg\n",
            "Running progressbar-2.5/setup.py -q bdist_egg --dist-dir /tmp/easy_install-1z2jmdn9/progressbar-2.5/egg-dist-tmp-wrerae92\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Adding progressbar 2.5 to easy-install.pth file\n",
            "detected new path './TorToiSe-2.3.0-py3.10.egg'\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/progressbar-2.5-py3.10.egg\n",
            "error: numpy 2.1.3 is installed but numpy<2.1,>=1.22 is required by {'numba'}\n"
          ]
        }
      ],
      "source": [
        "#@title Install tortoise original repository to be used to merge cloned audio pieces together\n",
        "!pip3 install -U scipy\n",
        "\n",
        "!git clone https://github.com/jnordberg/tortoise-tts.git\n",
        "%cd tortoise-tts\n",
        "!pip3 install -r requirements.txt\n",
        "!pip3 install transformers==4.19.0 einops==0.5.0 rotary_embedding_torch==0.1.5 unidecode==1.3.5\n",
        "!python3 setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtRwfD9gLv83",
        "outputId": "4d8cdecf-e852-4ca5-eddf-63b4975c209e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found the '|' character in your text, which I will use as a cue for where to split it up. If this was notyour intent, please remove all '|' characters from the input.\n"
          ]
        }
      ],
      "source": [
        "from tortoise.utils.text import split_and_recombine_text\n",
        "from time import time\n",
        "\n",
        "# Process text\n",
        "text = text_to_read\n",
        "if '|' in text:\n",
        "    print(\"Found the '|' character in your text, which I will use as a cue for where to split it up. If this was not\"\n",
        "          \"your intent, please remove all '|' characters from the input.\")\n",
        "    texts = text.split('|')\n",
        "else:\n",
        "    texts = split_and_recombine_text(text) #If only one piece of text (<20secs), convert it to list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUOhLGPELgpG",
        "outputId": "3cfe84ad-cf0e-4b6c-acd4-0bb7900b69f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/deepfake\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a100b0795dad4a9ea164df4ebd386eb5",
            "d5b0b0e7ff2345c6a4ee7ff49187b14f",
            "0c4a8741eda845f48bbd9c642b7562aa",
            "32675f6008ef4a5c89a09d4d75200e0a",
            "10a8c511e43945d6997ec45ce2a1e0d2",
            "0d4166eb72a64a6993958608d520ca2c",
            "b9df41907c654dac8d51c65c1114b8d2",
            "38fac5e3ef0345eeb435cd20413f04de",
            "66cb84298ac348769897ee1aa4d653e1",
            "e56b61e6ef744cb58a7b800c0c24e20f",
            "efc1238b08c64294bcbe04a837deb53e",
            "0fa8f89309314af986b528679aa8bfba",
            "e7e022b3b8c04614885c334133ef7584",
            "72fac962e64d43ff890291f6cb03db52",
            "39e1ef055aec4a90acb2dd5cd3e5cca0",
            "2a9f4e8c7dcd4a259dcc795d96db1292",
            "fcafff1152f345cba9905a5fc87ad671",
            "abdadd61f8734dc9b2da4a82bab21d63",
            "f1e73b986e8e49f398c1532f95733944",
            "1dace489b5b048d88ac3e5b12a690c46",
            "2fdf82462ccb416dbd112fdf2c3eb764",
            "03b8778dbf0a4f88992916855c797ec0",
            "d47cf40b09ae47d9b8a8d3277d96ea6a",
            "c5cb2a55040d403ab136a72f91c63f35",
            "0caf14b008a24b5dae8c7597822d143e",
            "8141981a91a84b0a960d96474f311326",
            "df3dda8364024e6c9099c912f4592bda",
            "a16094d0654e484185f4daa95a7ee0bf",
            "6c516b39b39c494eb73341d42e40c35b",
            "77d6b56b1dfe410fbbc89d17dbf73ac6",
            "3a8571cb5c3741399cf929f431c94819",
            "ffd0a9362ba747908e36e745bdce3c33",
            "d25f8f6ab3ba43679d63aaa60b69892d",
            "3f342fa468bd46f09ab60d7cea21b4fd",
            "f55368323cf84cd4bc3941b98a364f5a",
            "f874a63378a74a199478cc0aca6ace11",
            "8f3b933c92784128b4efc57bbf6bf42b",
            "ded9855f91154e86b0d47747869b7e4b",
            "f22a9234ed0545279797694ecdddb780",
            "855403fa43d948d496fef56463fc8a54",
            "848c70f9013b4ab88dbe688569166b03",
            "9efeddac6ffa4d89a82c198acdf35c09",
            "d9644118450e4f7b88b6408c6fb12f49",
            "4cb0c7c04c9e427e8db6243729564ee9",
            "d5ede865ed3f4ca28d75badaa5e63a13",
            "93917c60a23c40919aae26b347ddfa8d",
            "140434a1368f4ad19a4e92514bdacfd6",
            "a035e1e07c4843f1bf059100d1d35ecb",
            "6ac2380a8d09492c8dbd6a1758b52eac",
            "933c762a237144638e8158e8a7006c41",
            "7ed06f008f634a249100b3a860b46bce",
            "b8108a8020f247c493cb649c52dca3be",
            "48ba83dc66fd424280068b98babeb8a5",
            "7723f0204a1e4a82af5ece04b3dc3423",
            "5c551b7b948d42bbac695b56c3d2a266"
          ]
        },
        "id": "CTPX6hLLA-bW",
        "outputId": "59f083d1-c27b-465d-ccea-87eb8e9c8c04"
      },
      "outputs": [],
      "source": [
        "#Tortoise Fastest Inference from script (~2min per 20secs of audio in Colab)\n",
        "#Can also be downloaded from https://huggingface.co/jbetker/tortoise-tts-v2/tree/main\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "from TTS.tts.configs.tortoise_config import TortoiseConfig\n",
        "from TTS.tts.models.tortoise import Tortoise\n",
        "import IPython\n",
        "import gc\n",
        "\n",
        "config = TortoiseConfig()\n",
        "model = Tortoise.init_from_config(config)\n",
        "model.load_checkpoint(config, checkpoint_dir=\"/root/.local/share/tts/tts_models--en--multi-dataset--tortoise-v2\", eval=True) #Deepspeed doesn't work\n",
        "model.cuda()\n",
        "\n",
        "all_parts = []\n",
        "for j, text in enumerate(texts): #Combine individuals pieces of text by processing sound one piece at a time (around 20secs each)\n",
        "  # cloning a speaker\n",
        "  output_dict = model.synthesize(text, config, speaker_id=\"voice\", voice_dirs=base_path)\n",
        "\n",
        "  #Save result\n",
        "  torchaudio.save(\"tortoise_v2_script_\"+str(j)+\".wav\", torch.tensor(output_dict[\"wav\"]).squeeze(0), 24000)\n",
        "  all_parts.append(torch.tensor(output_dict[\"wav\"]).squeeze(0))\n",
        "  del output_dict\n",
        "\n",
        "  # Perform garbage collection\n",
        "  gc.collect()\n",
        "\n",
        "torchaudio.save('combined.wav', torch.cat(all_parts, dim=-1), 24000)\n",
        "IPython.display.Audio('combined.wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsrktP_DZUl3"
      },
      "source": [
        "Clean memory so that we can have a bit longer text to read"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Xjt6pDpvMVV5"
      },
      "outputs": [],
      "source": [
        "del all_parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PdGcmAfNpVPz"
      },
      "outputs": [],
      "source": [
        "for name in dir():\n",
        "    if not name.startswith('_'):\n",
        "        del globals()[name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3X1kF-MTu-",
        "outputId": "1c1c6da3-be07-4247-b2ec-381d7ac80984"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "# Perform garbage collection\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9vOyVxWKA-bY",
        "outputId": "214b7ab4-88bb-4624-aefa-0263bd490f07"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_9bbef104-2681-446a-9336-2f3f7984c83d\", \"combined.wav\", 928334)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/gdrive/MyDrive/deepfake/combined.wav')\n",
        "#Individual pieces can also be found in this folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4o_-0yd-GRC",
        "outputId": "5565664b-6fda-478c-fc93-2e2d430003b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.40k/4.40k [05:07<00:00, 14.3iB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Building video input_video.mp4.\n",
            "MoviePy - Writing audio in input_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "chunk:   0%|          | 0/427 [00:00<?, ?it/s, now=None]\u001b[A\n",
            "chunk:  28%|██▊       | 121/427 [00:00<00:00, 1202.65it/s, now=None]\u001b[A\n",
            "chunk:  57%|█████▋    | 242/427 [00:00<00:00, 1176.33it/s, now=None]\u001b[A\n",
            "chunk:  85%|████████▌ | 364/427 [00:00<00:00, 1194.86it/s, now=None]\u001b[A\n",
            "100%|██████████| 4.40k/4.40k [05:07<00:00, 14.3iB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video input_video.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "t:   0%|          | 0/484 [00:00<?, ?it/s, now=None]\u001b[A\n",
            "t:   2%|▏         | 9/484 [00:00<00:05, 89.23it/s, now=None]\u001b[A\n",
            "t:   4%|▎         | 18/484 [00:00<00:05, 82.06it/s, now=None]\u001b[A\n",
            "t:   6%|▌         | 28/484 [00:00<00:05, 87.97it/s, now=None]\u001b[A\n",
            "t:   8%|▊         | 38/484 [00:00<00:04, 90.99it/s, now=None]\u001b[A\n",
            "t:  10%|▉         | 48/484 [00:00<00:04, 93.12it/s, now=None]\u001b[A\n",
            "t:  12%|█▏        | 58/484 [00:00<00:06, 66.60it/s, now=None]\u001b[A\n",
            "t:  14%|█▎        | 66/484 [00:00<00:06, 60.89it/s, now=None]\u001b[A\n",
            "t:  15%|█▌        | 73/484 [00:01<00:07, 58.16it/s, now=None]\u001b[A\n",
            "t:  17%|█▋        | 80/484 [00:01<00:07, 54.99it/s, now=None]\u001b[A\n",
            "t:  18%|█▊        | 86/484 [00:01<00:07, 54.26it/s, now=None]\u001b[A\n",
            "t:  19%|█▉        | 92/484 [00:01<00:07, 51.54it/s, now=None]\u001b[A\n",
            "t:  20%|██        | 98/484 [00:01<00:07, 49.43it/s, now=None]\u001b[A\n",
            "t:  21%|██▏       | 104/484 [00:01<00:07, 48.19it/s, now=None]\u001b[A\n",
            "t:  23%|██▎       | 110/484 [00:01<00:07, 48.76it/s, now=None]\u001b[A\n",
            "t:  24%|██▍       | 115/484 [00:01<00:07, 49.04it/s, now=None]\u001b[A\n",
            "t:  25%|██▍       | 120/484 [00:02<00:07, 48.33it/s, now=None]\u001b[A\n",
            "t:  26%|██▌       | 126/484 [00:02<00:07, 49.75it/s, now=None]\u001b[A\n",
            "t:  27%|██▋       | 131/484 [00:02<00:08, 44.09it/s, now=None]\u001b[A\n",
            "t:  28%|██▊       | 136/484 [00:02<00:08, 41.55it/s, now=None]\u001b[A\n",
            "t:  29%|██▉       | 141/484 [00:02<00:08, 41.51it/s, now=None]\u001b[A\n",
            "t:  30%|███       | 146/484 [00:02<00:08, 42.02it/s, now=None]\u001b[A\n",
            "t:  31%|███       | 151/484 [00:02<00:08, 41.44it/s, now=None]\u001b[A\n",
            "t:  32%|███▏      | 157/484 [00:02<00:07, 43.31it/s, now=None]\u001b[A\n",
            "t:  34%|███▎      | 163/484 [00:03<00:06, 46.40it/s, now=None]\u001b[A\n",
            "t:  35%|███▍      | 169/484 [00:03<00:06, 49.51it/s, now=None]\u001b[A\n",
            "t:  36%|███▌      | 175/484 [00:03<00:06, 47.89it/s, now=None]\u001b[A\n",
            "t:  37%|███▋      | 181/484 [00:03<00:06, 50.23it/s, now=None]\u001b[A\n",
            "t:  39%|███▊      | 187/484 [00:03<00:06, 42.75it/s, now=None]\u001b[A\n",
            "t:  40%|███▉      | 192/484 [00:03<00:06, 42.33it/s, now=None]\u001b[A\n",
            "t:  41%|████      | 198/484 [00:03<00:06, 46.39it/s, now=None]\u001b[A\n",
            "t:  42%|████▏     | 204/484 [00:03<00:05, 48.13it/s, now=None]\u001b[A\n",
            "t:  43%|████▎     | 209/484 [00:04<00:05, 48.16it/s, now=None]\u001b[A\n",
            "t:  44%|████▍     | 214/484 [00:04<00:05, 48.59it/s, now=None]\u001b[A\n",
            "t:  45%|████▌     | 219/484 [00:04<00:05, 46.24it/s, now=None]\u001b[A\n",
            "t:  46%|████▋     | 225/484 [00:04<00:05, 46.40it/s, now=None]\u001b[A\n",
            "t:  48%|████▊     | 230/484 [00:04<00:05, 42.35it/s, now=None]\u001b[A\n",
            "t:  49%|████▊     | 235/484 [00:04<00:06, 38.27it/s, now=None]\u001b[A\n",
            "t:  50%|████▉     | 240/484 [00:04<00:06, 39.98it/s, now=None]\u001b[A\n",
            "t:  51%|█████     | 245/484 [00:04<00:05, 40.78it/s, now=None]\u001b[A\n",
            "t:  52%|█████▏    | 250/484 [00:05<00:05, 39.20it/s, now=None]\u001b[A\n",
            "t:  52%|█████▏    | 254/484 [00:05<00:05, 39.39it/s, now=None]\u001b[A\n",
            "t:  53%|█████▎    | 258/484 [00:05<00:05, 39.04it/s, now=None]\u001b[A\n",
            "t:  54%|█████▍    | 262/484 [00:05<00:06, 36.64it/s, now=None]\u001b[A\n",
            "t:  55%|█████▌    | 267/484 [00:05<00:05, 39.41it/s, now=None]\u001b[A\n",
            "t:  56%|█████▌    | 271/484 [00:05<00:05, 39.32it/s, now=None]\u001b[A\n",
            "t:  57%|█████▋    | 275/484 [00:05<00:06, 34.09it/s, now=None]\u001b[A\n",
            "t:  58%|█████▊    | 279/484 [00:05<00:06, 33.52it/s, now=None]\u001b[A\n",
            "t:  59%|█████▊    | 284/484 [00:05<00:05, 37.59it/s, now=None]\u001b[A\n",
            "t:  60%|█████▉    | 290/484 [00:06<00:04, 41.02it/s, now=None]\u001b[A\n",
            "t:  61%|██████    | 295/484 [00:06<00:05, 36.01it/s, now=None]\u001b[A\n",
            "t:  62%|██████▏   | 299/484 [00:06<00:05, 36.40it/s, now=None]\u001b[A\n",
            "t:  63%|██████▎   | 304/484 [00:06<00:04, 37.02it/s, now=None]\u001b[A\n",
            "t:  64%|██████▎   | 308/484 [00:06<00:05, 34.72it/s, now=None]\u001b[A\n",
            "t:  64%|██████▍   | 312/484 [00:06<00:04, 35.99it/s, now=None]\u001b[A\n",
            "t:  65%|██████▌   | 317/484 [00:06<00:04, 37.90it/s, now=None]\u001b[A\n",
            "t:  67%|██████▋   | 322/484 [00:06<00:03, 40.64it/s, now=None]\u001b[A\n",
            "t:  68%|██████▊   | 328/484 [00:07<00:03, 43.09it/s, now=None]\u001b[A\n",
            "t:  69%|██████▉   | 333/484 [00:07<00:03, 43.92it/s, now=None]\u001b[A\n",
            "t:  70%|██████▉   | 338/484 [00:07<00:03, 41.09it/s, now=None]\u001b[A\n",
            "t:  71%|███████   | 343/484 [00:07<00:03, 40.23it/s, now=None]\u001b[A\n",
            "t:  72%|███████▏  | 348/484 [00:07<00:03, 41.38it/s, now=None]\u001b[A\n",
            "t:  73%|███████▎  | 353/484 [00:07<00:03, 38.60it/s, now=None]\u001b[A\n",
            "t:  74%|███████▍  | 357/484 [00:07<00:03, 38.77it/s, now=None]\u001b[A\n",
            "t:  75%|███████▍  | 361/484 [00:07<00:03, 38.26it/s, now=None]\u001b[A\n",
            "t:  76%|███████▌  | 366/484 [00:08<00:03, 39.18it/s, now=None]\u001b[A\n",
            "t:  77%|███████▋  | 371/484 [00:08<00:02, 41.09it/s, now=None]\u001b[A\n",
            "t:  78%|███████▊  | 376/484 [00:08<00:02, 36.84it/s, now=None]\u001b[A\n",
            "t:  79%|███████▊  | 381/484 [00:08<00:02, 39.08it/s, now=None]\u001b[A\n",
            "t:  80%|███████▉  | 386/484 [00:08<00:02, 41.65it/s, now=None]\u001b[A\n",
            "t:  81%|████████  | 391/484 [00:08<00:02, 42.86it/s, now=None]\u001b[A\n",
            "t:  82%|████████▏ | 396/484 [00:08<00:02, 41.19it/s, now=None]\u001b[A\n",
            "t:  83%|████████▎ | 401/484 [00:08<00:02, 41.44it/s, now=None]\u001b[A\n",
            "t:  84%|████████▍ | 406/484 [00:09<00:02, 36.69it/s, now=None]\u001b[A\n",
            "t:  85%|████████▍ | 411/484 [00:09<00:01, 38.20it/s, now=None]\u001b[A\n",
            "t:  86%|████████▌ | 415/484 [00:09<00:01, 36.05it/s, now=None]\u001b[A\n",
            "t:  87%|████████▋ | 421/484 [00:09<00:01, 39.81it/s, now=None]\u001b[A\n",
            "t:  88%|████████▊ | 426/484 [00:09<00:01, 38.25it/s, now=None]\u001b[A\n",
            "t:  89%|████████▉ | 430/484 [00:09<00:01, 35.07it/s, now=None]\u001b[A\n",
            "t:  90%|████████▉ | 434/484 [00:09<00:01, 33.72it/s, now=None]\u001b[A\n",
            "t:  91%|█████████ | 439/484 [00:09<00:01, 34.88it/s, now=None]\u001b[A\n",
            "t:  92%|█████████▏| 445/484 [00:10<00:00, 39.90it/s, now=None]\u001b[A\n",
            "t:  93%|█████████▎| 451/484 [00:10<00:00, 42.00it/s, now=None]\u001b[A\n",
            "t:  94%|█████████▍| 456/484 [00:10<00:00, 37.41it/s, now=None]\u001b[A\n",
            "t:  95%|█████████▌| 460/484 [00:10<00:00, 37.90it/s, now=None]\u001b[A\n",
            "t:  96%|█████████▌| 464/484 [00:10<00:00, 37.65it/s, now=None]\u001b[A\n",
            "t:  97%|█████████▋| 468/484 [00:10<00:00, 37.21it/s, now=None]\u001b[A\n",
            "t:  98%|█████████▊| 474/484 [00:10<00:00, 41.16it/s, now=None]\u001b[A\n",
            "t:  99%|█████████▉| 479/484 [00:10<00:00, 42.24it/s, now=None]\u001b[A\n",
            "t: 100%|██████████| 484/484 [00:11<00:00, 42.34it/s, now=None]\u001b[A\n",
            "100%|██████████| 4.40k/4.40k [05:19<00:00, 13.8iB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready input_video.mp4\n"
          ]
        }
      ],
      "source": [
        "#@title Confirm that audio same length as video. If not, keep the smallest one and cut the other (or cut them both to 20secs). This is needed for wav2lip to work\n",
        "#ChatGPT Prompt: Create python code that compares an audio.wav with a video.mp4 files and if the duration of one is bigger than the other,\n",
        "# it cuts the largest one to be the same duration as the smallest. If any of them is bigger than 20secs then raise an error\n",
        "\n",
        "#Needed to avoid errors with encoding\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "import os\n",
        "\n",
        "def compare_audio_video_duration(audio_file, video_file):\n",
        "    audio = AudioFileClip(audio_file)\n",
        "    video = VideoFileClip(video_file)\n",
        "\n",
        "    audio_duration = audio.duration\n",
        "    video_duration = video.duration\n",
        "\n",
        "    # Either the video or audio should be <20 secs. If any of these is larger than that, it will be cut to the duration of the other or to 20secs.\n",
        "    # Might work for up to 30secs, but not guaranteed. If only video is provided, it will keep only the first 20 secs of it.\n",
        "\n",
        "    # if audio_duration > 20 and video_duration > 20:\n",
        "    #     video = video.subclip(0, 20)\n",
        "    #     video.write_videofile('input_video.mp4')\n",
        "    #     audio = audio.subclip(0, 20)\n",
        "    #     audio.write_audiofile('input_audio.wav')\n",
        "\n",
        "    if audio_duration != video_duration:\n",
        "        min_duration = min(audio_duration, video_duration)\n",
        "        if min_duration == audio_duration:\n",
        "            video = video.subclip(0, min_duration)\n",
        "            video.write_videofile('input_video.mp4')\n",
        "            os.rename(audio_file,'input_audio.wav')\n",
        "        else:\n",
        "            audio = audio.subclip(0, min_duration)\n",
        "            audio.write_audiofile('input_audio.wav')\n",
        "            os.rename(video_file,'input_video.mp4')\n",
        "\n",
        "    audio.close()\n",
        "    video.close()\n",
        "\n",
        "# Example usage\n",
        "compare_audio_video_duration(\"combined.wav\", \"video_full.mp4\") #input_voice.mp3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dT9AQwdf8sJK"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGEz5MihKSdY",
        "outputId": "a258666e-3f8b-4976-9e20-d7b99c6955ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qgo-oaI3JU2u",
        "outputId": "c9c4c04f-9e54-4e11-ea24-a50a9f242024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "#@title <h1>Install Wav2Lip</h1>\n",
        "#@markdown * Install dependencies\n",
        "#@markdown * Download models\n",
        "# !rm -rf /content/sample_data\n",
        "# !mkdir /content/sample_data\n",
        "\n",
        "!git clone https://github.com/zabique/Wav2Lip\n",
        "\n",
        "#download the pretrained model\n",
        "!wget 'https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA' -O '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'\n",
        "!wget 'https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/Eb3LEzbfuKlJiR600lQWRxgBIY27JZg80f7V9jtMfbNDaQ?e=TBFBVW' -O /content/Wav2Lip/checkpoints/wav2lip.pth\n",
        "!pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n",
        "\n",
        "# !pip uninstall tensorflow tensorflow-gpu\n",
        "!cd Wav2Lip && pip install -r requirements.txt\n",
        "\n",
        "#download pretrained model for face detection\n",
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth\"\n",
        "\n",
        "!pip install -q youtube-dl\n",
        "!pip install ffmpeg-python\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"\\nDone\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzokJMO19IyY"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgjaWJFs8B38"
      },
      "source": [
        "- Below implementation needs both audio and video to be of same length. Only specific extensions work (mp4 and wav)\n",
        "- Target face in the input_video.mp4, must be \"detectable\" in ALL videoframes (So no black or blurry frames etc)\n",
        "- wav2lip does not like very long and high res clips (1080p/30seconds recommended)\n",
        "- 'Wav2Lip' model gives highly accurate lip-sync compared to 'Wav2Lip + GAN' but with inferior visual quality compared to the latter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBvt_c2jdebP"
      },
      "source": [
        "Below is needed to fix an error in loading - Not added in the beginning due to conflict in dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "JLVZhHvL7GMo",
        "outputId": "8de4455c-a0b5-40ce-ec34-cce783b5a265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting librosa==0.9.1\n",
            "  Downloading librosa-0.9.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: audioread>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (3.0.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (4.4.2)\n",
            "Collecting resampy>=0.2.2 (from librosa==0.9.1)\n",
            "  Using cached resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.45.1->librosa==0.9.1) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.1) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.1) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.1) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa==0.9.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.1) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (2024.8.30)\n",
            "Downloading librosa-0.9.1-py3-none-any.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: resampy, librosa\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.0\n",
            "    Uninstalling librosa-0.10.0:\n",
            "      Successfully uninstalled librosa-0.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tts 0.22.0 requires einops>=0.6.0, but you have einops 0.5.0 which is incompatible.\n",
            "tts 0.22.0 requires librosa>=0.10.0, but you have librosa 0.9.1 which is incompatible.\n",
            "tts 0.22.0 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 2.0.2 which is incompatible.\n",
            "tts 0.22.0 requires transformers>=4.33.0, but you have transformers 4.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed librosa-0.9.1 resampy-0.4.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "d6602e2f8c34481abe88a461be7cd8fb",
              "pip_warning": {
                "packages": [
                  "librosa"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install librosa==0.9.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIgm4QcAUL1k",
        "outputId": "7d0f61e5-48fa-4b7c-b695-f58e37693471"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7768"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Clear all user-defined variables except built-in ones\n",
        "for name in dir():\n",
        "    if not name.startswith('_'):\n",
        "        del globals()[name]\n",
        "\n",
        "# Perform garbage collection to free up memory\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6wbZgRaY-fG",
        "outputId": "7f751611-2fb6-4131-a3ac-aca98305af37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==2.0.0\n",
            "  Downloading numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/60.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, pandas\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tts 0.22.0 requires einops>=0.6.0, but you have einops 0.5.0 which is incompatible.\n",
            "tts 0.22.0 requires librosa>=0.10.0, but you have librosa 0.9.1 which is incompatible.\n",
            "tts 0.22.0 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 2.0.0 which is incompatible.\n",
            "tts 0.22.0 requires pandas<2.0,>=1.4, but you have pandas 2.2.3 which is incompatible.\n",
            "tts 0.22.0 requires transformers>=4.33.0, but you have transformers 4.19.0 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.0.0 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.0 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "gruut 2.2.3 requires numpy<2.0.0,>=1.19.0, but you have numpy 2.0.0 which is incompatible.\n",
            "langchain 0.3.7 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.0.0 which is incompatible.\n",
            "matplotlib 3.8.0 requires numpy<2,>=1.21, but you have numpy 2.0.0 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "pytensor 2.25.5 requires numpy<2,>=1.17.0, but you have numpy 2.0.0 which is incompatible.\n",
            "sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.19.0 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.0.0 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.0.0 pandas-2.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -U numpy==2.0.0 pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR5utmDMcSZY",
        "outputId": "6d3caaaf-20f7-4f71-f8b5-5133ae5f0678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 484\n",
            "/content/Wav2Lip/audio.py:100: FutureWarning: Pass sr=16000, n_fft=800 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n",
            "(80, 1548)\n",
            "Length of mel chunks: 481\n",
            "  0% 0/4 [00:00<?, ?it/s]/content/Wav2Lip/face_detection/detection/sfd/sfd_detector.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_weights = torch.load(path_to_detector)\n",
            "\n",
            "  0% 0/31 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 1/31 [00:22<11:23, 22.80s/it]\u001b[A\n",
            "  6% 2/31 [00:24<04:59, 10.34s/it]\u001b[A\n",
            " 10% 3/31 [00:26<02:57,  6.35s/it]\u001b[A\n",
            " 13% 4/31 [00:27<02:00,  4.47s/it]\u001b[A\n",
            " 16% 5/31 [00:29<01:29,  3.43s/it]\u001b[A\n",
            " 19% 6/31 [00:30<01:10,  2.81s/it]\u001b[A\n",
            " 23% 7/31 [00:32<00:57,  2.41s/it]\u001b[A\n",
            " 26% 8/31 [00:33<00:49,  2.15s/it]\u001b[A\n",
            " 29% 9/31 [00:35<00:43,  1.99s/it]\u001b[A\n",
            " 32% 10/31 [00:37<00:39,  1.89s/it]\u001b[A\n",
            " 35% 11/31 [00:38<00:36,  1.80s/it]\u001b[A\n",
            " 39% 12/31 [00:40<00:33,  1.74s/it]\u001b[A\n",
            " 42% 13/31 [00:42<00:30,  1.70s/it]\u001b[A\n",
            " 45% 14/31 [00:43<00:28,  1.67s/it]\u001b[A\n",
            " 48% 15/31 [00:45<00:26,  1.65s/it]\u001b[A\n",
            " 52% 16/31 [00:46<00:24,  1.65s/it]\u001b[A\n",
            " 55% 17/31 [00:48<00:22,  1.64s/it]\u001b[A\n",
            " 58% 18/31 [00:50<00:21,  1.64s/it]\u001b[A\n",
            " 61% 19/31 [00:51<00:19,  1.64s/it]\u001b[A\n",
            " 65% 20/31 [00:53<00:18,  1.64s/it]\u001b[A\n",
            " 68% 21/31 [00:55<00:16,  1.63s/it]\u001b[A\n",
            " 71% 22/31 [00:56<00:14,  1.62s/it]\u001b[A\n",
            " 74% 23/31 [00:58<00:13,  1.63s/it]\u001b[A\n",
            " 77% 24/31 [00:59<00:11,  1.63s/it]\u001b[A\n",
            " 81% 25/31 [01:01<00:09,  1.62s/it]\u001b[A\n",
            " 84% 26/31 [01:03<00:08,  1.62s/it]\u001b[A\n",
            " 87% 27/31 [01:04<00:06,  1.62s/it]\u001b[A\n",
            " 90% 28/31 [01:06<00:04,  1.62s/it]\u001b[A\n",
            " 94% 29/31 [01:08<00:03,  1.62s/it]\u001b[A\n",
            " 97% 30/31 [01:09<00:01,  1.62s/it]\u001b[A\n",
            "100% 31/31 [01:11<00:00,  2.31s/it]\n",
            "Load checkpoint from: checkpoints/wav2lip_gan.pth\n",
            "/content/Wav2Lip/inference.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n",
            "Model loaded\n",
            "100% 4/4 [01:32<00:00, 23.00s/it]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from '/content/gdrive/MyDrive/deepfake/input_audio.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Duration: 00:00:19.34, bitrate: 384 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:00:19.24, start: 0.000000, bitrate: 1533 kb/s\n",
            "  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 960x540 [SAR 1:1 DAR 16:9], 1529 kb/s, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
            "\u001b[0m\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mprofile High, level 3.1, 4:2:0, 8-bit\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'results/result_voice.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 960x540 [SAR 1:1 DAR 16:9], q=2-31, 25 fps, 12800 tbn\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 24000 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "frame=  481 fps=241 q=-1.0 Lsize=    1046kB time=00:00:19.32 bitrate= 443.5kbits/s speed=9.68x    \n",
            "video:868kB audio:167kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.122372%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mframe I:2     Avg QP:18.94  size: 47638\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mframe P:303   Avg QP:21.44  size:  2322\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mframe B:176   Avg QP:27.81  size:   508\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mconsecutive B-frames: 46.8% 11.6%  5.0% 36.6%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mmb I  I16..4:  8.7% 84.0%  7.3%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mmb P  I16..4:  0.2%  1.0%  0.1%  P16..4: 10.0%  4.0%  3.0%  0.0%  0.0%    skip:81.7%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mmb B  I16..4:  0.1%  0.4%  0.0%  B16..8: 11.5%  0.7%  0.1%  direct: 0.2%  skip:87.1%  L0:39.5% L1:56.3% BI: 4.2%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0m8x8 transform intra:82.1% inter:72.5%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mcoded y,uvDC,uvAC intra: 59.2% 55.7% 20.2% inter: 4.0% 4.1% 0.4%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mi16 v,h,dc,p: 20% 47% 22% 11%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 18% 34% 31%  2%  2%  2%  3%  2%  4%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 32% 11%  3%  5%  6%  6%  5%  4%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mi8c dc,h,v,p: 44% 35% 18%  4%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mref P L0: 74.6% 13.6%  8.7%  3.1%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mref B L0: 89.7%  8.5%  1.8%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mref B L1: 97.0%  3.0%\n",
            "\u001b[1;36m[libx264 @ 0x574d09ce3100] \u001b[0mkb/s:369.26\n",
            "\u001b[1;36m[aac @ 0x574d09cefc80] \u001b[0mQavg: 415.888\n"
          ]
        }
      ],
      "source": [
        "#@title Create Wav2Lip video (using wav2lip_gan.pth) GAN\n",
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face '/content/gdrive/MyDrive/deepfake/input_video.mp4' --audio '/content/gdrive/MyDrive/deepfake/input_audio.wav' --resize_factor 2\n",
        "\n",
        "#Use --resize_factor 2 otherwise OOM error. Use resize_factor to reduce the video resolution, as there is a chance you might get better results for lower resolution videos.\n",
        "# This might be related with the model which might have been trained on low resolution faces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "d_bgh-aqA-bc",
        "outputId": "8b1bb97c-3570-4b0e-fa94-80c85f7687b6"
      },
      "outputs": [],
      "source": [
        "#@title Play result video -  50% scaling\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n",
        "\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"50%\" height=\"50%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1kt-krsEbz5j",
        "outputId": "851dbb4d-7409-4553-a910-26e213bbf784"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_38ef16b0-33de-4edc-b0c7-05a7848eecad\", \"result_voice.mp4\", 1071614)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_08614e0f-57b2-4eb6-b30a-3046ea7e70c2\", \"input_audio.wav\", 928334)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Download Result.mp4 to your computer\n",
        "from google.colab import files\n",
        "files.download('/content/Wav2Lip/results/result_voice.mp4') #Only after the last cell is executed this will start\n",
        "files.download('/content/gdrive/MyDrive/deepfake/input_audio.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT8njpBCJ7gD"
      },
      "outputs": [],
      "source": [
        "# #@title Delete old uploaded samples & result files, so you can start over again.\n",
        "# # %rm /content/sample_data/*\n",
        "# %rm /content/Wav2Lip/results/*\n",
        "# from IPython.display import clear_output\n",
        "# clear_output()\n",
        "# print(\"\\nDone! now press X\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7zgfrQqbKom"
      },
      "source": [
        "# **Variations to try**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmcEzPH3TDBg"
      },
      "outputs": [],
      "source": [
        "# #@title Create Wav2Lip video using wav2lip.pth\n",
        "# !cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\"  --resize_factor 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45XW4SZAzIz5"
      },
      "outputs": [],
      "source": [
        "#@title Use more padding to include the chin region (you can manually edit pads dimensions viewing and changing the code)\n",
        "# !cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\" --pads 0 20 0 0 --resize_factor 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1Z0zRdZR5BZ"
      },
      "outputs": [],
      "source": [
        "# #@title Play result video -  50% scaling\n",
        "# from IPython.display import HTML\n",
        "# from base64 import b64encode\n",
        "# mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n",
        "# data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "# HTML(f\"\"\"\n",
        "# <video width=\"50%\" height=\"50%\" controls>\n",
        "#       <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "# </video>\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfXFOpAmR_dh"
      },
      "outputs": [],
      "source": [
        "#@title Download Result.mp4 to your computer\n",
        "# from google.colab import files\n",
        "# files.download('/content/Wav2Lip/results/result_voice.mp4')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03b8778dbf0a4f88992916855c797ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c4a8741eda845f48bbd9c642b7562aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38fac5e3ef0345eeb435cd20413f04de",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66cb84298ac348769897ee1aa4d653e1",
            "value": 100
          }
        },
        "0caf14b008a24b5dae8c7597822d143e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77d6b56b1dfe410fbbc89d17dbf73ac6",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a8571cb5c3741399cf929f431c94819",
            "value": 100
          }
        },
        "0d4166eb72a64a6993958608d520ca2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fa8f89309314af986b528679aa8bfba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7e022b3b8c04614885c334133ef7584",
              "IPY_MODEL_72fac962e64d43ff890291f6cb03db52",
              "IPY_MODEL_39e1ef055aec4a90acb2dd5cd3e5cca0"
            ],
            "layout": "IPY_MODEL_2a9f4e8c7dcd4a259dcc795d96db1292"
          }
        },
        "10a8c511e43945d6997ec45ce2a1e0d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "140434a1368f4ad19a4e92514bdacfd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8108a8020f247c493cb649c52dca3be",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48ba83dc66fd424280068b98babeb8a5",
            "value": 100
          }
        },
        "1dace489b5b048d88ac3e5b12a690c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a9f4e8c7dcd4a259dcc795d96db1292": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fdf82462ccb416dbd112fdf2c3eb764": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32675f6008ef4a5c89a09d4d75200e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e56b61e6ef744cb58a7b800c0c24e20f",
            "placeholder": "​",
            "style": "IPY_MODEL_efc1238b08c64294bcbe04a837deb53e",
            "value": " 100/100 [00:10&lt;00:00,  9.12it/s]"
          }
        },
        "38fac5e3ef0345eeb435cd20413f04de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39e1ef055aec4a90acb2dd5cd3e5cca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fdf82462ccb416dbd112fdf2c3eb764",
            "placeholder": "​",
            "style": "IPY_MODEL_03b8778dbf0a4f88992916855c797ec0",
            "value": " 100/100 [00:17&lt;00:00,  5.83it/s]"
          }
        },
        "3a8571cb5c3741399cf929f431c94819": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f342fa468bd46f09ab60d7cea21b4fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f55368323cf84cd4bc3941b98a364f5a",
              "IPY_MODEL_f874a63378a74a199478cc0aca6ace11",
              "IPY_MODEL_8f3b933c92784128b4efc57bbf6bf42b"
            ],
            "layout": "IPY_MODEL_ded9855f91154e86b0d47747869b7e4b"
          }
        },
        "48ba83dc66fd424280068b98babeb8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cb0c7c04c9e427e8db6243729564ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c551b7b948d42bbac695b56c3d2a266": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66cb84298ac348769897ee1aa4d653e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ac2380a8d09492c8dbd6a1758b52eac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c516b39b39c494eb73341d42e40c35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72fac962e64d43ff890291f6cb03db52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1e73b986e8e49f398c1532f95733944",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dace489b5b048d88ac3e5b12a690c46",
            "value": 100
          }
        },
        "7723f0204a1e4a82af5ece04b3dc3423": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77d6b56b1dfe410fbbc89d17dbf73ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ed06f008f634a249100b3a860b46bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8141981a91a84b0a960d96474f311326": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffd0a9362ba747908e36e745bdce3c33",
            "placeholder": "​",
            "style": "IPY_MODEL_d25f8f6ab3ba43679d63aaa60b69892d",
            "value": " 100/100 [00:10&lt;00:00,  9.28it/s]"
          }
        },
        "848c70f9013b4ab88dbe688569166b03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "855403fa43d948d496fef56463fc8a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f3b933c92784128b4efc57bbf6bf42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9644118450e4f7b88b6408c6fb12f49",
            "placeholder": "​",
            "style": "IPY_MODEL_4cb0c7c04c9e427e8db6243729564ee9",
            "value": " 100/100 [00:06&lt;00:00, 16.54it/s]"
          }
        },
        "933c762a237144638e8158e8a7006c41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93917c60a23c40919aae26b347ddfa8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_933c762a237144638e8158e8a7006c41",
            "placeholder": "​",
            "style": "IPY_MODEL_7ed06f008f634a249100b3a860b46bce",
            "value": "100%"
          }
        },
        "9efeddac6ffa4d89a82c198acdf35c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a035e1e07c4843f1bf059100d1d35ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7723f0204a1e4a82af5ece04b3dc3423",
            "placeholder": "​",
            "style": "IPY_MODEL_5c551b7b948d42bbac695b56c3d2a266",
            "value": " 100/100 [00:06&lt;00:00, 16.36it/s]"
          }
        },
        "a100b0795dad4a9ea164df4ebd386eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5b0b0e7ff2345c6a4ee7ff49187b14f",
              "IPY_MODEL_0c4a8741eda845f48bbd9c642b7562aa",
              "IPY_MODEL_32675f6008ef4a5c89a09d4d75200e0a"
            ],
            "layout": "IPY_MODEL_10a8c511e43945d6997ec45ce2a1e0d2"
          }
        },
        "a16094d0654e484185f4daa95a7ee0bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abdadd61f8734dc9b2da4a82bab21d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8108a8020f247c493cb649c52dca3be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9df41907c654dac8d51c65c1114b8d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5cb2a55040d403ab136a72f91c63f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a16094d0654e484185f4daa95a7ee0bf",
            "placeholder": "​",
            "style": "IPY_MODEL_6c516b39b39c494eb73341d42e40c35b",
            "value": "100%"
          }
        },
        "d25f8f6ab3ba43679d63aaa60b69892d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d47cf40b09ae47d9b8a8d3277d96ea6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5cb2a55040d403ab136a72f91c63f35",
              "IPY_MODEL_0caf14b008a24b5dae8c7597822d143e",
              "IPY_MODEL_8141981a91a84b0a960d96474f311326"
            ],
            "layout": "IPY_MODEL_df3dda8364024e6c9099c912f4592bda"
          }
        },
        "d5b0b0e7ff2345c6a4ee7ff49187b14f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d4166eb72a64a6993958608d520ca2c",
            "placeholder": "​",
            "style": "IPY_MODEL_b9df41907c654dac8d51c65c1114b8d2",
            "value": "100%"
          }
        },
        "d5ede865ed3f4ca28d75badaa5e63a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93917c60a23c40919aae26b347ddfa8d",
              "IPY_MODEL_140434a1368f4ad19a4e92514bdacfd6",
              "IPY_MODEL_a035e1e07c4843f1bf059100d1d35ecb"
            ],
            "layout": "IPY_MODEL_6ac2380a8d09492c8dbd6a1758b52eac"
          }
        },
        "d9644118450e4f7b88b6408c6fb12f49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ded9855f91154e86b0d47747869b7e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df3dda8364024e6c9099c912f4592bda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e56b61e6ef744cb58a7b800c0c24e20f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7e022b3b8c04614885c334133ef7584": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcafff1152f345cba9905a5fc87ad671",
            "placeholder": "​",
            "style": "IPY_MODEL_abdadd61f8734dc9b2da4a82bab21d63",
            "value": "100%"
          }
        },
        "efc1238b08c64294bcbe04a837deb53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1e73b986e8e49f398c1532f95733944": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f22a9234ed0545279797694ecdddb780": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f55368323cf84cd4bc3941b98a364f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f22a9234ed0545279797694ecdddb780",
            "placeholder": "​",
            "style": "IPY_MODEL_855403fa43d948d496fef56463fc8a54",
            "value": "100%"
          }
        },
        "f874a63378a74a199478cc0aca6ace11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_848c70f9013b4ab88dbe688569166b03",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9efeddac6ffa4d89a82c198acdf35c09",
            "value": 100
          }
        },
        "fcafff1152f345cba9905a5fc87ad671": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd0a9362ba747908e36e745bdce3c33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
